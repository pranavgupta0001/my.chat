{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM7koNFIS2RODy0snVlzjVN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavgupta0001/my.chat/blob/main/test/cfc_rag_0001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#details\n",
        "The simple rag on CropManage data, just through the data in and it will take produce the answers."
      ],
      "metadata": {
        "id": "tG2prg66_qJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#imports\n"
      ],
      "metadata": {
        "id": "d2MrTsY-pKik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBS5MuNT78Vk",
        "outputId": "7e596275-f297-455a-deea-697aeb961720"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.9/2.5 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgvKivkg7_jq",
        "outputId": "df4f469b-5b52-428f-9277-84a37cd657b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.4)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n",
            "  Downloading openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.58.1-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.57.4\n",
            "    Uninstalling openai-1.57.4:\n",
            "      Successfully uninstalled openai-1.57.4\n",
            "Successfully installed langchain-openai-0.2.14 openai-1.58.1 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlWof5O47_pm",
        "outputId": "6ec6c9eb-393d-436c-fcca-73f3adde6dfb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.2 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "seL9PjwFpFcr"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import getpass\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Credentials"
      ],
      "metadata": {
        "id": "pubf6x5mpNSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your environment variables for LangChain and OpenAI\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # Enables LangSmith (LangChain) tracing if needed\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "dc2XNor2pV1t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model and embeddings"
      ],
      "metadata": {
        "id": "sDJzR22KpprV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your model and embeddings\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ],
      "metadata": {
        "id": "hQoejZsmpqmw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loader\n"
      ],
      "metadata": {
        "id": "Bk3Hb8ydpr3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def json_to_langchain_full_docs(file_path: str) -> list[Document]:\n",
        "    \"\"\"\n",
        "    Reads a CropManage JSON file, extracts the resource_description\n",
        "    and the main data content, then returns a list of LangChain Documents.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    data_str = \"All Data:\\n\" + json.dumps(data)\n",
        "    doc = Document(\n",
        "        page_content=data_str,\n",
        "        metadata={\n",
        "            \"file_name\": file_path\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return [doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwyMdTR-9o8k",
        "outputId": "a651a49b-3fc4-4335-8c32-a2830b1cd524"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Data:\n",
            "{\"CommodityType\": {\"endpoint\": \"https://api.dev.cropmanage.ucanr.edu/v2/commodity-types.json\", \"description\": \"Returns a complete list of commodity types in CropManage.\", \"resource_description\": {\"inputs_description\": {}, \"outputs_description\": {\"Id\": {\"description\": \"commodity type ID\", \"type\": \"integer\"}, \"Name\": {\"description\": \"commodity type name\", \"type\": \"string\"}, \"IconPath\": {\"description\": \"commodity type icon path, used in planting settings\", \"type\": \"string\"}, \"HarvestOnce\" ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import data"
      ],
      "metadata": {
        "id": "2TGwbA2Xp8sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage for the CommodityType.json file:\n",
        "file_path = \"/content/CommodityType.json\"  # Replace with your actual path in Google Colab or local environment\n",
        "docs = json_to_langchain_full_docs(file_path)\n",
        "\n",
        "# Inspect the text if curious:\n",
        "print(docs[0].page_content[:500], \"...\")"
      ],
      "metadata": {
        "id": "gj7UPHuvp_XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text splitting\n",
        "for better retrieval"
      ],
      "metadata": {
        "id": "oYQHx_EdqACj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
        "\n",
        "split_docs = []\n",
        "for doc in docs:\n",
        "    for chunk in text_splitter.split_text(doc.page_content):\n",
        "        split_docs.append(\n",
        "            Document(page_content=chunk, metadata=doc.metadata)\n",
        "        )\n",
        "\n",
        "print(f\"Number of splitted docs: {len(split_docs)}\")"
      ],
      "metadata": {
        "id": "MauzbSFt92w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pinecone"
      ],
      "metadata": {
        "id": "kF79cYVbp6iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "# Name your Pinecone Index\n",
        "index_name = \"cropmanage-index\"\n",
        "\n",
        "# Initialize Pinecone client using userdata for API key (This part is correct)\n",
        "pc = Pinecone(api_key=userdata.get('PINECONE_API_KEY'))\n",
        "\n",
        "# Ensure the index exists (create it if needed)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(index_name, dimension=3072, metric=\"cosine\", spec={'serverless': {'cloud': 'aws', 'region': 'us-east-1'}})\n",
        "\n",
        "# Connect to the existing index\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# **CHANGED:** Instead of using `Pinecone.from_documents`, we instantiate `PineconeVectorStore`\n",
        "# directly, passing in the existing `pc` client. This avoids the problem with LangChain's internal\n",
        "# Pinecone initialization that doesn't use your API key from `userdata`.\n",
        "\n",
        "vectorstore = PineconeVectorStore(\n",
        "    embedding=embeddings,\n",
        "    index=index,             # <--- pass in your pc.Index object\n",
        ")"
      ],
      "metadata": {
        "id": "yO7QORsAp0uG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upsert\n",
        "to Pinecone"
      ],
      "metadata": {
        "id": "zMQWdv8XqHsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = vectorstore.add_documents(documents=docs)"
      ],
      "metadata": {
        "id": "gEnEHWmDqL_y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retriever and Generator\n"
      ],
      "metadata": {
        "id": "Gp4Xueh2qNxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",  # or \"mmr\" / \"similarity_score_threshold\"\n",
        "    search_kwargs={\"k\": 3}     # retrieve top 3 relevant chunks\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",  # or \"map_reduce\", \"refine\" for longer contexts\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True  # useful for debugging\n",
        ")"
      ],
      "metadata": {
        "id": "G1AVH9oS_ASY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Queries"
      ],
      "metadata": {
        "id": "RpIf8Ahs_EmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query 1: Harvest frequency of Walnut and Strawberry?\n",
        "query = \"What is the harvest frequency of Walnut and Strawberry?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "print(\"Query:\", query)\n",
        "print(\"Answer:\", result[\"result\"])\n",
        "print(\"\\nSources:\")\n",
        "for src in result[\"source_documents\"]:\n",
        "    print(src.metadata, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixcaGh78_HEi",
        "outputId": "4c0843d5-2b99-4169-95c5-f504a7ee7fb6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-0d7c6d9e728d>:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is the harvest frequency of Walnut and Strawberry?\n",
            "Answer: Walnut has a harvest frequency of \"not harvested once\" (it is harvested multiple times), and Strawberry has a harvest frequency of \"not harvested once\" (it is also harvested multiple times).\n",
            "\n",
            "Sources:\n",
            "{'file_name': '/content/CommodityType.json', 'top_level_key': 'CommodityType'} \n",
            "\n",
            "{'file_name': '/content/CommodityType.json', 'top_level_key': 'CommodityType'} \n",
            "\n",
            "{'file_name': '/content/CommodityType.json', 'top_level_key': 'CommodityType'} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"Which crops can I manage?\",\n",
        "    \"What are the commodity types available for my ranch in California?\",\n",
        "    \"Is alfalfa a supported crop?\",\n",
        "    \"Is onion a supported crop?\",\n",
        "    \"Is watermelon harvested once or multiple times?\",\n",
        "    \"What is the harvest frequency of watermelon?\",\n",
        "    \"is Tomato supported and whats its harvest frequency\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    res = qa_chain({\"query\": q})\n",
        "    print(\"\\nQuery:\", q)\n",
        "    print(\"Answer:\", res[\"result\"])\n",
        "    print(\"Sources:\", [d.metadata[\"file_name\"] for d in res[\"source_documents\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvYX57Lt_OVM",
        "outputId": "fc886109-5d9c-4422-8061-72968b392ea6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Which crops can I manage?\n",
            "Answer: I don't know.\n",
            "Sources: ['/content/CommodityType.json', '/content/CommodityType.json', '/content/CommodityType.json']\n",
            "\n",
            "Query: What are the commodity types available for my ranch in California?\n",
            "Answer: I don't know.\n",
            "Sources: ['/content/CommodityType.json', '/content/CommodityType.json', '/content/CommodityType.json']\n",
            "\n",
            "Query: Is alfalfa a supported crop?\n",
            "Answer: Yes, alfalfa is a supported crop, but it is currently marked as inactive.\n",
            "Sources: ['/content/CommodityType.json', '/content/CommodityType.json', '/content/CommodityType.json']\n",
            "\n",
            "Query: Is onion a supported crop?\n",
            "Answer: Yes, onion is a supported crop. It can be harvested once.\n",
            "Sources: ['/content/CommodityType.json', '/content/CommodityType.json', '/content/CommodityType.json']\n",
            "\n",
            "Query: Is watermelon harvested once or multiple times?\n",
            "Answer: Watermelon is harvested once.\n",
            "Sources: ['/content/CommodityType.json', '/content/CommodityType.json', '/content/CommodityType.json']\n",
            "\n",
            "Query: What is the harvest frequency of watermelon?\n",
            "Answer: The harvest frequency of watermelon is once, as it is marked as \"HarvestOnce\": true.\n",
            "Sources: ['/content/CommodityType.json', '/content/CommodityType.json', '/content/CommodityType.json']\n",
            "\n",
            "Query: is Tomato supported and whats its harvest frequency\n",
            "Answer: Yes, Tomato is supported and it can be harvested once.\n",
            "Sources: ['/content/CommodityType.json', '/content/CommodityType.json', '/content/CommodityType.json']\n"
          ]
        }
      ]
    }
  ]
}